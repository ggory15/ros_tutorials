{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "\n",
    "This tutorial session is devoted to learn how to simulate sensors within Gazebo_ros.\n",
    "\n",
    "## Provided packages\n",
    "\n",
    "```\n",
    "git clone https://github.com/ggory15/ros_tutorials\n",
    "```\n",
    "\n",
    "or\n",
    "\n",
    "```\n",
    "git pull origin master\n",
    "```\n",
    "\n",
    "### Add Gazebo model\n",
    "```\n",
    "gedit ~/.bashrc\n",
    "```\n",
    "\n",
    "Then, \n",
    "```\n",
    "export GAZEBO_MODEL_PATH={Your Workspace}/1027_tutorial/gazebo_sensor_tutorial/models/:${GAZEBO_MODEL_PATh}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensors in Gazebo and ROS\n",
    "\n",
    "Related to sensors, Gazebo provides:\n",
    "\n",
    "1. The [gazebo_models repository](https://github.com/osrf/gazebo_models) with some SDF models of sensors that include geometric descriptions and sensor features, like the camera.\n",
    "2. A set of [sensor classes](http://osrf-distributions.s3.amazonaws.com/gazebo/api/dev/group__gazebo__sensors.html), like [CameraSensor](http://osrf-distributions.s3.amazonaws.com/gazebo/api/dev/classgazebo_1_1sensors_1_1CameraSensor.html), that define the behavior of the sensors. All of them inherit from class Sensor.\n",
    "3. A set of plugins, like the [camera plugin](http://osrf-distributions.s3.amazonaws.com/gazebo/api/dev/classgazebo_1_1CameraPlugin.html), that interface the corresponding sensor classes. They inherit from a general sensor plugin class that has access to the Sensor class.\n",
    "\n",
    "Because Gazebo and ROS are separate projects that do not depend on each other, ROS sensor plugins have been implemented to wrap the Gazebo sensor plugins. The available ROS sensor plugins are available in the gazebo_plugins of gazebo_ros_pkgs, like those related to cameras and depth cameras.\n",
    "\n",
    "Plugins can be added to SDF sensor models or to sensor models defined using URDF.\n",
    "\n",
    "The cameras and depth camera sensors will be described next, their ROS plugins and their modeling using both SDF and URDF. Plugins for other sensors will be just listed in section ROS plugins for other sensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Camera Sensor\n",
    "### The Camera ROS plugin\n",
    "\n",
    "The camera ROS plugin provides the ROS interface for simulating cameras by publishing the sensor_msgs::CameraInfo and sensor_msgs::Image ROS messages.\n",
    "The ROS camera plugin is libgazebo_ros_camera.so. Some implementation details are included in Section Plugin implementation.\n",
    "To associate the plugin to a given camera model, the following XML code has to be included in the SDF or URDF model description:\n",
    "\n",
    "```\n",
    "<plugin name=\"camera_controller\" filename=\"libgazebo_ros_camera.so\">\n",
    "  <alwaysOn>true</alwaysOn>\n",
    "  <updateRate>0.0</updateRate>\n",
    "  <cameraName>camera</cameraName>\n",
    "  <imageTopicName>image_raw</imageTopicName>\n",
    "  <cameraInfoTopicName>camera_info</cameraInfoTopicName>\n",
    "  <frameName>camera_link_optical</frameName>\n",
    "  <!-- setting hackBaseline to anything but 0.0 will cause a misalignment\n",
    "           between the gazebo sensor image and the frame it is supposed to\n",
    "           be attached to -->\n",
    "  <hackBaseline>0.0</hackBaseline>\n",
    "  <distortionK1>0.0</distortionK1>\n",
    "  <distortionK2>0.0</distortionK2>\n",
    "  <distortionK3>0.0</distortionK3>\n",
    "  <distortionT1>0.0</distortionT1>\n",
    "  <distortionT2>0.0</distortionT2>\n",
    "  <CxPrime>0</CxPrime>\n",
    "  <Cx>0.0</Cx>\n",
    "  <Cy>0.0</Cy>\n",
    "  <focalLength>0.0</focalLength>\n",
    "</plugin>\n",
    "```\n",
    "\n",
    "The main arguments to be particularized are:\n",
    "\n",
    "        <cameraName>: the camera name (camera)\n",
    "\n",
    "        <imageTopicName>: the topic name of the advertised sensor_msgs::Image message (image_raw)\n",
    "\n",
    "        <cameraInfoTopicName>: the topic name of the advertised sensor_msgs::CameraInfo message (camera_info)\n",
    "\n",
    "        <frameName>: the coordinate frame the image is published under in the tf tree (camera_link_optical)\n",
    "\n",
    "The <updateRate> is usually set to zero, which causes the plugin to publish information at the same rate as the parent SDF sensor (which is specified in the field <update_rate>, see below).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exersice 1\n",
    "\n",
    "Take a look at the file model.sdf in the folder models/camera-plugin of the gazebo_sensors_tutorial package.\n",
    "\n",
    "A launch file is provided to test this sensor model; it loads this camera and a coke can. The image message advertised can be visualized in rviz (that uses the camera_coke2.rviz configuration file where the Image Topic has been set to /camera/image_raw). The launch file to run rviz uses a static_transform_publisher to visualize the camera reference frame (called camera_link_optical):\n",
    "\n",
    "```\n",
    "roslaunch gazebo_sensors_tutorial camera_coke_gazebo2.launch\n",
    "```\n",
    "```\n",
    "rostopic list\n",
    "rostopic echo /camera/camera_info\n",
    "roslaunch gazebo_sensors_tutorial camera_coke_rviz2.launch\n",
    "```\n",
    "![image1](./image/fig1a.png)\n",
    "![image2](./image/fig1b.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A URDF model\n",
    "\n",
    "URDF robot models may contain description of sensors with the associated plugins. As an example, package rrbot_description includes in the rrbot.xacro file an end-effector link called camera_link associated to a camera. It contains all the visual and collision geometric descriptions (in this case a simple cube). Complementary, the rrbot.gazebo file contains an associated <gazebo> tag that includes the <sensor> element (that is directly passed to the <sdf> model) with the camera features and the plugin used with the following key information:\n",
    "\n",
    "1. the camera name (rrbot/camera1)\n",
    "2. the topic name of the advertised sensor_msgs::Image message (image_raw)\n",
    "3. the topic name of the advertised sensor_msgs::CameraInfo message (camera_info)\n",
    "4. the coordinate frame the image is published under in the tf tree (camera_link)\n",
    "\n",
    "```\n",
    "rence=\"camera_link\">\n",
    "   <sensor type=\"camera\" name=\"camera1\">\n",
    "     <update_rate>30.0</update_rate>\n",
    "     <camera name=\"head\">\n",
    "       <horizontal_fov>1.3962634</horizontal_fov>\n",
    "       <image>\n",
    "         <width>800</width>\n",
    "         <height>800</height>\n",
    "         <format>R8G8B8</format>\n",
    "       </image>\n",
    "       <clip>\n",
    "         <near>0.02</near>\n",
    "         <far>300</far>\n",
    "       </clip>\n",
    "       <noise>\n",
    "         <type>gaussian</type>\n",
    "         <!-- Noise is sampled independently per pixel on each frame.\n",
    "              That pixel's noise value is added to each of its color\n",
    "              channels, which at that point lie in the range [0,1]. -->\n",
    "         <mean>0.0</mean>\n",
    "         <stddev>0.007</stddev>\n",
    "       </noise>\n",
    "     </camera>\n",
    "     <plugin name=\"camera_controller\" filename=\"libgazebo_ros_camera.so\">\n",
    "       <alwaysOn>true</alwaysOn>\n",
    "       <updateRate>0.0</updateRate>\n",
    "       <cameraName>rrbot/camera1</cameraName>\n",
    "       <imageTopicName>image_raw</imageTopicName>\n",
    "       <cameraInfoTopicName>camera_info</cameraInfoTopicName>\n",
    "       <frameName>camera_link_optical</frameName>\n",
    "       <!-- setting hackBaseline to anything but 0.0 will cause a misalignment\n",
    "           between the gazebo sensor image and the frame it is supposed to\n",
    "           be attached to -->\n",
    "       <hackBaseline>0.0</hackBaseline>\n",
    "       <distortionK1>0.0</distortionK1>\n",
    "       <distortionK2>0.0</distortionK2>\n",
    "       <distortionK3>0.0</distortionK3>\n",
    "       <distortionT1>0.0</distortionT1>\n",
    "       <distortionT2>0.0</distortionT2>\n",
    "       <CxPrime>0</CxPrime>\n",
    "       <Cx>0.0</Cx>\n",
    "       <Cy>0.0</Cy>\n",
    "       <focalLength>0.0</focalLength>\n",
    "     </plugin>\n",
    "   </sensor>\n",
    " </gazebo>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exersice 2\n",
    "\n",
    "The advertised images can be visualized using rviz. Follow the instruction below to load the rrbot and a coke can and to open rviz (in this case the Image Topic field is filled with the topic /rrbot/camera1/image_raw).\n",
    "\n",
    "\n",
    "A launch file is provided to test this sensor model; it loads this camera and a coke can. The image message advertised can be visualized in rviz (that uses the camera_coke2.rviz configuration file where the Image Topic has been set to /camera/image_raw). The launch file to run rviz uses a static_transform_publisher to visualize the camera reference frame (called camera_link_optical):\n",
    "\n",
    "```\n",
    "roslaunch rrbot_gazebo rrbot_world_2.launch\n",
    "rosrun gazebo_ros spawn_model -database coke_can -sdf -model coke_can -y 0.5 -x -1.2\n",
    "roslaunch rrbot_description rrbot_rviz_2.launch\n",
    "```\n",
    "![image3](./image/fig2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The depth camera sensor\n",
    "### The depth camera ROS plugin\n",
    "\n",
    "The depth camera ROS plugin simulates a depth sensor like an Xbox-Kinect. The depth camera ROS plugin provides the ROS interface for simulating depth cameras by publishing the sensor_msgs::CameraInfo, sensor_msgs::Image and sensor_msgs::PointCloud2 ROS messages.\n",
    "\n",
    "The ROS depth camera plugin is libgazebo_ros_openni_kinect.so. Some implementation details are included in Section Plugin implementation.\n",
    "\n",
    "To associate the plugin to a given depth camera model, the following XML code has to be included in the SDF or URDF model description:\n",
    "\n",
    "```\n",
    "<plugin name=\"camera_plugin\" filename=\"libgazebo_ros_openni_kinect.so\">\n",
    "  <baseline>0.2</baseline>\n",
    "  <alwaysOn>true</alwaysOn>\n",
    "  <!-- Keep this zero, update_rate in the parent <sensor> tag\n",
    "       will control the frame rate. -->\n",
    "  <updateRate>20.0</updateRate>\n",
    "  <cameraName>camera_ir</cameraName>\n",
    "  <imageTopicName>/camera/color/image_raw</imageTopicName>\n",
    "  <cameraInfoTopicName>/camera/color/camera_info</cameraInfoTopicName>\n",
    "  <depthImageTopicName>/camera/depth/image_raw</depthImageTopicName>\n",
    "  <depthImageCameraInfoTopicName>/camera/depth/camera_info</depthImageCameraInfoTopicName>\n",
    "  <pointCloudTopicName>/camera/depth/points</pointCloudTopicName>\n",
    "  <frameName>depth_camera_link</frameName>\n",
    "  <pointCloudCutoff>0.05</pointCloudCutoff>\n",
    "  <distortionK1>0</distortionK1>\n",
    "  <distortionK2>0</distortionK2>\n",
    "  <distortionK3>0</distortionK3>\n",
    "  <distortionT1>0</distortionT1>\n",
    "  <distortionT2>0</distortionT2>\n",
    "  <CxPrime>0</CxPrime>\n",
    "  <Cx>0</Cx>\n",
    "  <Cy>0</Cy>\n",
    "  <focalLength>0</focalLength>\n",
    "  <hackBaseline>0</hackBaseline>\n",
    "</plugin>\n",
    "```\n",
    "\n",
    "The main arguments to be particularized are:\n",
    "\n",
    "        the camera name (camera_ir)\n",
    "\n",
    "        the name of the image topic (sensor_msgs::Image message /camera/color/image_raw)\n",
    "\n",
    "        the name of the camera info topic (sensor_msgs::CameraInfo message /camera/color/camera_info)\n",
    "\n",
    "        the name of the depth image topic (sensor_msgs::Image message /camera/depth/image_raw)\n",
    "\n",
    "        the name of the depth camera info (sensor_msgs::CameraInfo message /camera/depth/camera_info) - this is the same as the camera info topic, but is only advertised when someone is subcribed to the other depth topics.\n",
    "\n",
    "        the name of the point cloud topic (sensor_msgs::PointCloud2 message /camera/depth/points)\n",
    "\n",
    "        the coordinate frame the data is published under in the tf tree (depth_camera_link)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exersice 3\n",
    "\n",
    "Take a look at the file model.sdf in the folder models/kinect-plugin of the gazebo_sensors_tutorial package.\n",
    "\n",
    "A launch file is provided to test this sensor model; it loads this kinect sensor and a coke can. The image message advertised can be visualized in rviz:\n",
    "\n",
    "```\n",
    "roslaunch gazebo_sensors_tutorial kinect_coke_gazebo2.launch\n",
    "```\n",
    "```\n",
    "roslaunch gazebo_sensors_tutorial kinect_coke_rviz.launch\n",
    "```\n",
    "![image1](./image/fig3a.png)\n",
    "![image2](./image/fig3b.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exersice 4\n",
    "\n",
    "Take a look at the following files in the urdf/sensors folder of the mastering_ros_robot_description_pkg package:\n",
    "\n",
    "    xtion_pro_live.gazebo.xacro, where a xacro:macro is used to define the depth camera sensor and its plugin,\n",
    "\n",
    "    xtion_pro_live.urdf.xacro, where a xacro:macro is used to define the camera geometry and reference frames\n",
    "\n",
    "\n",
    "```\n",
    "roslaunch seven_dof_arm_gazebo seven_dof_arm_with_rgbd_world.launch\n",
    "rosrun gazebo_ros spawn_model -database coke_can -sdf -model coke_can -x 0.4\n",
    "roslaunch gazebo_sensors_tutorial kinect_arm_rviz.launch\n",
    "```\n",
    "![image1](./image/fig4.png)\n",
    "![image2](./image/fig4b.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Sensors\n",
    "\n",
    "### ArUco library\n",
    "As an application example, the estimation of the poses of objects will be tackled using the ArUco library, an open-source library for fast camera pose estimation using squared markers, and the aruco_ros package that wraps it. There are two alternatives nodes:\n",
    "\n",
    "1. The aruco_ros nodes of type single look for a given marker ID and if found publishes several messages with its information (e.g. a geometry_msgs/PoseStamped with the pose and a visualization_msgs/Marker with the rviz marker), and a tf added to the tf_tree.\n",
    "2. The aruco_ros nodes of type marker_publisher publishes a message of type aruco_msgs/MarkerArray with the information of the IDs and poses of all the markers found.\n",
    "\n",
    "### Exercise 5\n",
    "Move the pose of the cubes using the gazebo GUI and check how the new poses are tracked in rviz.\n",
    "\n",
    "```\n",
    "roslaunch gazebo_sensors_tutorial camera_gazebo2.launch\n",
    "rosrun gazebo_ros spawn_model -database aruco_cube -sdf -model aruco_cube  -x 0.11 -z 0.05\n",
    "rosrun gazebo_ros spawn_model -database pawnB1 -sdf -model pawnB1 -x 0.1 -y -0.1 -z 0.02\n",
    "```\n",
    "\n",
    "Then run the following launch file that:\n",
    "    1. Starts two ArUco nodes, tuned to detect each of the two markers by specifying:\n",
    "        \n",
    "        the marker ID,\n",
    "        \n",
    "        the marker size,\n",
    "        \n",
    "        the marker frame\n",
    "        \n",
    "        the reference frame\n",
    "\n",
    "    2. A node that subscribes to the published marker poses and broadcasts a transform located at the center of the objects.\n",
    "    3. Starts rviz to visualize the detected markers and all the transforms.\n",
    "\n",
    "```\n",
    "roslaunch gazebo_sensors_tutorial camera_aruco_cube_rviz-2.launch\n",
    "\n",
    "```\n",
    "\n",
    "![image1](./image/fig5a.png)\n",
    "\n",
    "If there are many markers to be detected all of the same size, a node of type marker_publisher should be run. The aruco_msgs/MarkerArray will contain the information of the detecte markers, but no tf are broadcasted. To do so, the package aruco_broadcater has a node of type aruco_broadcaster that broadcasts a tf of any marker detected by the marker_publisher node.\n",
    "\n",
    "This is illustrated in the following example:\n",
    "```\n",
    "roslaunch gazebo_sensors_tutorial camera_gazebo2_cubes.launch\n",
    "roslaunch gazebo_sensors_tutorial camera_aruco_cube_rviz-aruco_broadcaster.launch\n",
    "```\n",
    "\n",
    "The aruco_broadcaster node is configured with a yaml file with information regarding: a) which markers should be published; b) the frame w.r.t. the arucos are referred; c) the prefix of the tf that will be used, e.g. aruco_.\n",
    "\n",
    "```\n",
    "  markerList: []\n",
    "\n",
    "  # the frame w.r.t. the arucos are referred\n",
    "  camera_frame: camera_link_optical\n",
    "\n",
    "  # the prefix of the tf that will be used\n",
    "  aruco_frame: aruco\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Example (Chess demo)\n",
    "\n",
    "An example has been prepared with two D415 cameras and a chessboard and two chess pieces labeled with ArUco makers. The world reference frame is located at the center of the chessboard.\n",
    "\n",
    "```\n",
    "roslaunch gazebo_sensors_tutorial cameras_chessboard.launch\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
